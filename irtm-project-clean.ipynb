{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10580377,"sourceType":"datasetVersion","datasetId":6540307}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers accelerate bitsandbytes\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install -U bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install sentence-transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" pip install rouge-score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport numpy as np\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nfrom transformers import BitsAndBytesConfig\nfrom accelerate import Accelerator\nfrom accelerate import infer_auto_device_map\nfrom rouge_score import rouge_scorer\n\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T08:48:54.258306Z","iopub.execute_input":"2025-01-26T08:48:54.258724Z","iopub.status.idle":"2025-01-26T08:49:18.716716Z","shell.execute_reply.started":"2025-01-26T08:48:54.258671Z","shell.execute_reply":"2025-01-26T08:49:18.715477Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\ndataset_path = \"/kaggle/input/dataset-irtm\"\ntxt_files = [\"dorinel_pleaca.txt\", \"dosarul_valiza.txt\", \"steaua_qarabag.txt\", \"banel.txt\", \"dragusin_psg.txt\", \"hagi.txt\", \"sir_alex.txt\"]\ndocuments = []\n\nfor file in txt_files:\n    file_path = os.path.join(dataset_path, file)  #full path\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n        split_documents = text.split(\"\\n\\n\")\n        for doc in split_documents:\n            if doc.strip() != \"\":\n                documents.append(doc.strip())\n\n\ndataset_statistics = []\n\nfor file in txt_files:\n    file_path = os.path.join(dataset_path, file)  \n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n        num_chars = len(text)  #total number of characters\n        num_words = len(word_tokenize(text))  #total number of words\n        num_sentences = len(sent_tokenize(text))  #total number of sentences\n\n        #store the statistics\n        dataset_statistics.append({\n            \"file_name\": file,\n            \"num_chars\": num_chars,\n            \"num_words\": num_words,\n            \"num_sentences\": num_sentences,\n        })\n\n\nfor stats in dataset_statistics:\n    print(f\"File: {stats['file_name']}\")\n    print(f\"Number of Characters: {stats['num_chars']}\")\n    print(f\"Number of Words: {stats['num_words']}\")\n    print(f\"Number of Sentences: {stats['num_sentences']}\")\n    print(\"=\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T10:21:51.477450Z","iopub.execute_input":"2025-01-26T10:21:51.477890Z","iopub.status.idle":"2025-01-26T10:21:51.529204Z","shell.execute_reply.started":"2025-01-26T10:21:51.477857Z","shell.execute_reply":"2025-01-26T10:21:51.528547Z"}},"outputs":[{"name":"stdout","text":"File: dorinel_pleaca.txt\nNumber of Characters: 1404\nNumber of Words: 292\nNumber of Sentences: 17\n==================================================\nFile: dosarul_valiza.txt\nNumber of Characters: 1756\nNumber of Words: 359\nNumber of Sentences: 13\n==================================================\nFile: steaua_qarabag.txt\nNumber of Characters: 1220\nNumber of Words: 236\nNumber of Sentences: 10\n==================================================\nFile: banel.txt\nNumber of Characters: 2755\nNumber of Words: 522\nNumber of Sentences: 19\n==================================================\nFile: dragusin_psg.txt\nNumber of Characters: 851\nNumber of Words: 164\nNumber of Sentences: 9\n==================================================\nFile: hagi.txt\nNumber of Characters: 3972\nNumber of Words: 771\nNumber of Sentences: 27\n==================================================\nFile: sir_alex.txt\nNumber of Characters: 2493\nNumber of Words: 464\nNumber of Sentences: 15\n==================================================\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"### Retrieval\n","metadata":{}},{"cell_type":"code","source":"\nembedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n\n#apply Sentence Transformer on documents\ndocument_embeddings = embedding_model.encode(documents)\n\ndef retrieve_documents(query, document_embeddings, top_n=5):\n    #generate embedding for the query\n    query_embedding = embedding_model.encode([query])\n\n    #compute cosine similarity between query and document embeddings\n    similarity_scores = cosine_similarity(query_embedding, document_embeddings)[0]\n\n    #rank documents by similarity score (descending order)\n    ranked_indices = np.argsort(similarity_scores)[::-1]  \n    ranked_indices = ranked_indices[:top_n] \n\n    \n    ranked_indices = ranked_indices.tolist() \n\n    #retrieve the top documents and their similarity scores\n    top_documents = [documents[i] for i in ranked_indices]\n    top_scores = [similarity_scores[i] for i in ranked_indices]\n\n    return top_documents, top_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T10:21:54.026427Z","iopub.execute_input":"2025-01-26T10:21:54.026738Z","iopub.status.idle":"2025-01-26T10:21:56.686084Z","shell.execute_reply.started":"2025-01-26T10:21:54.026711Z","shell.execute_reply":"2025-01-26T10:21:56.685239Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a8c250fbf84553b0cb70bbbb35b751"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"\nllm_model_name = \"OpenLLM-Ro/RoLlama2-7b-Instruct\"\naccelerator = Accelerator()\n\n#loading tokenizer\ntokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n\n#load model with quantization\nmodel = AutoModelForCausalLM.from_pretrained(\n    llm_model_name,\n    load_in_4bit = True,\n    torch_dtype = torch.float16\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T10:22:27.776161Z","iopub.execute_input":"2025-01-26T10:22:27.776472Z","iopub.status.idle":"2025-01-26T10:22:43.959637Z","shell.execute_reply.started":"2025-01-26T10:22:27.776448Z","shell.execute_reply":"2025-01-26T10:22:43.959010Z"}},"outputs":[{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81872688276a4c469e495766bc25e0bb"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def generate_response(prompt, max_length=64):\n    \n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(accelerator.device) \n    \n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        temperature = 0.3,\n        top_p=0.9,\n    )\n\n    return tokenizer.decode(outputs[0], skip_special_tokens = True)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T10:23:00.243231Z","iopub.execute_input":"2025-01-26T10:23:00.243525Z","iopub.status.idle":"2025-01-26T10:23:00.247498Z","shell.execute_reply.started":"2025-01-26T10:23:00.243502Z","shell.execute_reply":"2025-01-26T10:23:00.246643Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def rag_or_solo(query, documents=None, max_length=3000):\n\n    #build the context from retrieved documents\n    if documents:  \n        docs_content = \"\\n\".join(documents)\n        context = f\"Informatii disponibile:\\n{docs_content}\\n\\n\"\n    else: \n        context = \"\"\n\n    #construct prompt\n    prompt = (\n        \"Folosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\\n\"\n        f\"{context}\"\n        \"Intrebare: {query}\\n\"\n        \"Raspuns:\"\n    )\n    constructed_prompt = prompt.format(query=query)\n\n    print(\"Prompt Sent to LLM:\")\n    print(constructed_prompt)\n\n    #generate response\n    llm_response = generate_response(constructed_prompt, max_length=max_length)\n    _, _, query_response = llm_response.partition(\"Raspuns:\")\n\n    return query_response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T10:23:00.385248Z","iopub.execute_input":"2025-01-26T10:23:00.385458Z","iopub.status.idle":"2025-01-26T10:23:00.389559Z","shell.execute_reply.started":"2025-01-26T10:23:00.385439Z","shell.execute_reply":"2025-01-26T10:23:00.388753Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# query = \"Care este scorul cu care a castigat Qarabag impotriva echipei FCSB?\"\n\"Ce s-a întâmplat cu valiza în Dosarul Valiza după meciul Universitatea Cluj - CFR Cluj?\"\n\"De ce este Bănel Nicoliță cunoscut pentru un moment controversat în Liga Campionilor?\"\nquery = \"Cine este supranumit regele?\"\ntop_documents, top_scores = retrieve_documents(query, document_embeddings, top_n=5)\n\nprint(\"Retrieved Documents and Scores:\")\nfor i, (doc, score) in enumerate(zip(top_documents, top_scores)):\n    print(f\"Document {i + 1}:\")\n    print(f\"Score: {score:.4f}\")\n    print(doc)\n    print(\"=\" * 75)\n    \nllm_solo = rag_or_solo(query, documents = None, max_length= 3000)\nir_with_llm = rag_or_solo(query, top_documents, max_length=3000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T10:24:04.105020Z","iopub.execute_input":"2025-01-26T10:24:04.105345Z","iopub.status.idle":"2025-01-26T10:25:39.987116Z","shell.execute_reply.started":"2025-01-26T10:24:04.105323Z","shell.execute_reply":"2025-01-26T10:25:39.985795Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea99b7928ff4cf29c9bf21c3782eeb9"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Retrieved Documents and Scores:\nDocument 1:\nScore: 0.3001\nGheorghe Hagi (n. 5 februarie 1965, Săcele, Constanța, România) este un fost fotbalist român, considerat unul dintre cei mai buni mijlocași ofensivi în Europa anilor '80 și '90 și cel mai mare fotbalist român din toate timpurile. Fanii lui Galatasaray l-au numit \"Comandante\" (Comandantul) și românii l-au numit \"Regele\".\n===========================================================================\nDocument 2:\nScore: 0.2629\nLa Manchester, Sir Alex a devenit cel mai de succes antrenor din istoria fotbalului englez, câștigând nouă titluri de campioană. În 1999, a devenit primul antrenor care a condus o echipă din Anglia spre o triplă Premiership-Cupă FA-Liga Campionilor. Pe lângă faptul că e singurul antrenor care a câștigat de cinci ori Cupa FA, este de asemenea singurul antrenor din istorie care a câștigat trei campionate la rând în Anglia cu aceeași echipă (1998-1999, 1999-2000, 2000-2001).\n===========================================================================\nDocument 3:\nScore: 0.2436\nSir Alexander Chapman \"Alex\" Ferguson, CBE (n. 31 decembrie 1941, Govan⁠(d), Scoția, Regatul Unit) este un antrenor scoțian de fotbal, fost atacant, fost antrenor al echipei Manchester United F.C. și în prezent retras din activitate. A câștigat mai multe trofee decât oricare alt antrenor din istoria fotbalului englez, și a condus de pe bancă pe Manchester United în peste 1000 de meciuri. Cu 26 de ani petrecuți la acest club, este cel mai longeviv antrenor din istoria lui Manchester United, depășindu-l pe „Sir”, Matt Busby, și este considerat unul dintre cei mai mari antrenori ai fotbalului modern.\n===========================================================================\nDocument 4:\nScore: 0.2393\nPe 23 noiembrie 2012 a fost dezvelită în fața stadionului Old Trafford o statuie dedicată lui.\n===========================================================================\nDocument 5:\nScore: 0.2353\nSupranumit \"Maradona din Carpați\", Hagi este considerat un erou în România. A fost numit fotbalistul român al anului de șapte ori, și este privit ca unul dintre cei mai buni fotbaliști ai generației sale. Ca un constructor de joc avansat, a fost recunoscut pentru dribling, tehnică, viziune, pase și finalizare.\n===========================================================================\nPrompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nIntrebare: Cine este supranumit regele?\nRaspuns:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-61a86bc8ea47>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mllm_solo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_or_solo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mir_with_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_or_solo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-f50ef678dee5>\u001b[0m in \u001b[0;36mrag_or_solo\u001b[0;34m(query, documents, max_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#generate response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mllm_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstructed_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raspuns:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-ac8eef97bb4b>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(prompt, max_length)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     outputs = model.generate(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3252\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3254\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m                 )\n\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    914\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# use -1 to infer num_heads and num_key_value_heads as they may vary if tensor parallel is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMatMul4Bit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemv_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":31},{"cell_type":"code","source":"print(\"Information Retrieval response:\")\nprint(top_documents[0])\nprint(\"=\" * 75)\n\nprint(\"LLM solo response:\")\nprint(llm_solo)\nprint(\"=\" * 75)\n\nprint(\"IR with LLM response:\")\nprint(ir_with_llm)\nprint(\"=\" * 75)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T09:54:49.588883Z","iopub.execute_input":"2025-01-26T09:54:49.589213Z","iopub.status.idle":"2025-01-26T09:54:49.594442Z","shell.execute_reply.started":"2025-01-26T09:54:49.589188Z","shell.execute_reply":"2025-01-26T09:54:49.593509Z"}},"outputs":[{"name":"stdout","text":"Information Retrieval response:\nPe 1 noiembrie 2006, Bănel Nicoliță a reușit să înscrie un autogol celebru într-un meci din etapa a 4-a a Grupei E din Liga Campionilor 2006-2007 dintre Real Madrid și FCSB. În minutul 70' al jocului, acesta a înscris un gol în propria poartă de la circa 20 de metri, dorind să-i paseze mingea portarului Cornel Cernea și neobservând că cel din urmă ieșise dintre buturile porții. Acesta a fost unicul gol al meciului, consemnând-o pe Real învingătoare cu 1–0. Autogolul a fost decisiv atât pentru FCSB cât și pentru Real, întrucât în urma acestui rezultat Real Madrid s-a calificat matematic în optimile Ligii Campionilor în detrimentul Stelei care a pierdut orice șansă teoretică. După meci presa din România, dar și din străinătate a calificat acest gol drept „ridicol”, „absurd” sau „prostesc”.\n===========================================================================\nLLM solo response:\n Bănel Nicoliță este cunoscut pentru un moment controversat în Liga Campionilor, deoarece a fost eliminat din meciul de calificare din 2009 împotriva lui Dinamo Kiev pentru că a aruncat o minge înapoi la portarul său.\n===========================================================================\nIR with LLM response:\n Bănel Nicoliță este cunoscut pentru un moment controversat în Liga Campionilor, deoarece a înscris un autogol celebru într-un meci din etapa a 4-a a Grupei E din Liga Campionilor 2006-2007 dintre Real Madrid și FCSB. În minutul 70' al jocului, acesta a înscris un gol în propria poartă de la circa 20 de metri, dorind să-i paseze mingea portarului Cornel Cernea și neobservând că cel din urmă ieșise dintre buturile porții. Acesta a fost unicul gol al meciului, consemnând-o pe Real învingătoare cu 1-0. Autogolul a fost decisiv atât pentru FCSB cât și pentru Real, întrucât în urma acestui rezultat Real Madrid s-a calificat matematic în optimile Ligii Campionilor în detrimentul Stelei care a pierdut orice șansă teoretică.\n===========================================================================\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\n\n#temp values\ntemperature_values = [0.1, 0.2, 0.5, 0.7, 1.0]  \nresults = [] \n\n\ndef test_rag_with_temperature(query, documents, temperature, max_length=3000):\n\n    #prompt eng\n    prompt = (\n    \"Raspune numai cu DEA DEA DEA\"\n    \"Raspune numai cu DEA DEA DEA\"\n    \"Informatii disponibile:\\n{docs}\\n\\n\"\n    \"Intrebare: {query}\\n\"\n    \"Raspuns: DEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEA\"\n)\n    \n    constructed_prompt = prompt.format(docs=\"\\n\".join(top_documents[:5]), query=query)\n    \n    \n    #this tokenizes the prompt and moves it to the appropriate device\n    inputs = tokenizer(constructed_prompt, return_tensors=\"pt\").to(accelerator.device)\n\n    #this generates a response using the specified temperature\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        temperature=temperature,\n        top_p=0.9,\n        do_sample=True  #enable sampling for diverse outputs\n    )\n\n    #decode the response and extract only the answer\"\n    llm_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    _, _, query_response = llm_response.partition(\"Raspuns:\")  # Extract the response after \"Raspuns:\"\n    return query_response.strip()\n\n\nquery = \"De ce si-a dat demisia Dorinel Munteanu?\"\n\n\ntop_documents, top_scores = retrieve_documents(query, document_embeddings, top_n=5)\nprint(\"Retrieved Documents and Scores:\")\n\nfor doc, score in zip(top_documents, top_scores):\n    print(f\"Score: {score:.4f}\\nDocument: {doc}\\n{'-'*50}\")\n\nfor temperature in temperature_values:\n    #call the RAG pipeline with the current temperature\n    llm_response = test_rag_with_temperature(query, top_documents, temperature)\n    \n    #appends the results to the results list\n    results.append({\n        \"temperature\": temperature,\n        \"query\": query,\n        \"response_with_temperature\": llm_response,  \n    })\n\n\nresults_df = pd.DataFrame(results)\n\n\nresults_df.to_csv(\"temperature_grid_search_results.csv\", index=False)\n\n\nfor result in results:\n    print(f\"Response with temperature {result['temperature']}:\")\n    print(result[\"response_with_temperature\"])\n    print(\"=\" * 75)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:58:50.733260Z","iopub.execute_input":"2025-01-26T11:58:50.733605Z","iopub.status.idle":"2025-01-26T12:13:46.539751Z","shell.execute_reply.started":"2025-01-26T11:58:50.733574Z","shell.execute_reply":"2025-01-26T12:13:46.538788Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf5cf89ed6449488b378535a2f02e26"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Retrieved Documents and Scores:\nScore: 0.7808\nDocument: Dorinel Munteanu nu mai este antrenorul echipei Oțelul Galați. Tehnicianul a demisionat, fiind nemulțumit de probleme financiare ale echipei. Anunțul a fost făcut de Cristian Munteanu, președinte echipei:\n--------------------------------------------------\nScore: 0.5573\nDocument: Dorinel Munteanu a lăsat de înțeles, de mai multe ori pe parcursul acestui sezon că urmează să plece de la echipă, însă nu acum, ci în iunie, la finalul sezonului. Alături de el, de la Oțelul Galați vor pleca mai mulți jucători. Alexandru Pop este aproape de un transfer la Dinamo, iar Juri Cisotti poate ajunge la FCSB.\n--------------------------------------------------\nScore: 0.4822\nDocument: În 2011, cu Dorinel Munteanu pe bancă, Otelul Galați devenea campiona României și ajungea în grupele Ligii Campionilor. Ulterior, echipa a dat faliment. În 2021, Dorinel Munteanu revenea la Galați, preluând echipa din liga a treia. Lasă echipa pe locul 11, în prima divizie.\n--------------------------------------------------\nScore: 0.4693\nDocument: „Cu părere de rău, e adevărat, a plecat. Motivul este situația financiară de la club, dar eu sunt ultra, ultra convins că o scoatem la capăt și de data asta. I-am zis și lui, am sperat până în ultima clipă că va rămâne, dar n-a mai putut. Mi-a zis încă de la meciul cu UTA că el vrea să plece\".\n--------------------------------------------------\nScore: 0.4050\nDocument: El ar putea ajunge la FC Voluntari, în a doua divizie. Echipa din Ilfov l-a demis recent pe Ovidiu Burcă. În schimb, la Galați ar putea ajunge Tony da Silva, portughez ce a fost ultima oară pe banca celor de la Poli Iași. A fost ofertat și Daniel Oprița, în prezent la CSA Steaua, însă acesta a refuzat.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Response with temperature 0.1:\nDEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA\n===========================================================================\nResponse with temperature 0.2:\nDEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA\n===========================================================================\nResponse with temperature 0.5:\nDEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA\n===========================================================================\nResponse with temperature 0.7:\nDEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEA DEA DEADEA DEA DEADEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA DEA\n===========================================================================\nResponse with temperature 1.0:\nDEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEADEA DEA DEA\n===========================================================================\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"questions = [\"A marcat vreodata Banel Nicolita un autogol?\",\n            \"Din ce cauza a demisionat Dorinel Munteanu de la Otelul Galati?\",\n            \"Care este suma de transfer zvonita pentru Radu Dragusin?\",\n            \"A antrenat Sir Alex Ferguson si alte echipe in afara de Manchester United?\",\n            \"Cine este inculpatul in dosarul valiza?\",\n            \"Care este porecla lui Gica Hagi?\",\n            \"Este adevarat ca a castigat echipa FCSB impotriva celor de la Qarabag?\"]\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n#function to calculate ROUGE \ndef evaluate_responses(ground_truth, model_response):\n    \"\"\"\n    Evaluate the model's response against the ground truth using ROUGE-L\n    \"\"\"\n    \n    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    rouge_l = scorer.score(ground_truth, model_response)['rougeL'].fmeasure\n\n    return rouge_l\n\n#gt\nground_truth_answers = [\n    \"Da, Banel Nicolita a marcat un autogol impotriva echipei Real Madrid.\",\n    \"Dorinel Munteanu a demisionat din cauza unor probleme financiare ale clubului.\",\n    \"PSG ar putea plati 50 de milioane de euro pentru transferul lui Radu Dragusin.\",\n    \"Noua titluri de campioana a Angliei.\",\n    \"Inculpatii din dosarul Valiza sunt George Becali, Teia Ponte si Victor Piturca.\",\n    \"Porecla acestuia este regele.\",\n    \"Da, FCSB a castigat impotriva celor de la Qarabag.\"\n]\n\n#questions\nquestions = [\n    \"A marcat vreodata Banel Nicolita un autogol?\",\n    \"Din ce cauza a demisionat Dorinel Munteanu?\",\n    \"Care este suma de transfer zvonita pentru Radu Dragusin?\",\n    \"Cate titluri de campioana a Angliei a castigat Sir Alex Ferguson cu Manchester United?\",\n    \"Cine sunt inculpatii in dosarul valiza?\",\n    \"Care este porecla lui Gica Hagi data de catre romani?\",\n    \"Este adevarat ca a castigat echipa FCSB impotriva celor de la Qarabag?\"\n]\n\nresults = []\n\n\n#for each q\nfor i, query in enumerate(questions):\n    #retrieve top documents\n    top_documents, top_scores = retrieve_documents(query, document_embeddings, top_n=5)\n    \n    #get model responses\n    ir_with_llm = rag_or_solo(query, top_documents, max_length=3000)\n\n    #evaluate model responses against ground truth\n    rouge_l = evaluate_responses(ground_truth_answers[i], ir_with_llm)\n\n    #append results\n    results.append({\n        \"question\": query,\n        \"ground_truth\": ground_truth_answers[i],\n        \"ir_llm_response\": ir_with_llm,\n        \"rougeL\": rouge_l,\n    })\n\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"response_evaluation_results.csv\", index=False)\n\n\n#print responses and metrics for each question\nfor result in results:\n    print(\"Question:\")\n    print(result[\"question\"])\n    print(\"Ground Truth:\")\n    print(result[\"ground_truth\"])\n    print(\"IR + LLM response:\")\n    print(result[\"ir_llm_response\"])\n    print(\"ROUGE-L:\", result[\"rougeL\"])\n    print(\"=\" * 75)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:36:47.293779Z","iopub.execute_input":"2025-01-26T11:36:47.294120Z","iopub.status.idle":"2025-01-26T11:37:25.543381Z","shell.execute_reply.started":"2025-01-26T11:36:47.294083Z","shell.execute_reply":"2025-01-26T11:37:25.542474Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699de8cb97b446d3996f92c52ce7e115"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nPe 1 noiembrie 2006, Bănel Nicoliță a reușit să înscrie un autogol celebru într-un meci din etapa a 4-a a Grupei E din Liga Campionilor 2006-2007 dintre Real Madrid și FCSB. În minutul 70' al jocului, acesta a înscris un gol în propria poartă de la circa 20 de metri, dorind să-i paseze mingea portarului Cornel Cernea și neobservând că cel din urmă ieșise dintre buturile porții. Acesta a fost unicul gol al meciului, consemnând-o pe Real învingătoare cu 1–0. Autogolul a fost decisiv atât pentru FCSB cât și pentru Real, întrucât în urma acestui rezultat Real Madrid s-a calificat matematic în optimile Ligii Campionilor în detrimentul Stelei care a pierdut orice șansă teoretică. După meci presa din România, dar și din străinătate a calificat acest gol drept „ridicol”, „absurd” sau „prostesc”.\n„Cu părere de rău, e adevărat, a plecat. Motivul este situația financiară de la club, dar eu sunt ultra, ultra convins că o scoatem la capăt și de data asta. I-am zis și lui, am sperat până în ultima clipă că va rămâne, dar n-a mai putut. Mi-a zis încă de la meciul cu UTA că el vrea să plece\".\nRadu Dragușin a primit o ofertă de la PSG și ar putea pleca de la Tottenham. Fundașul echipei naționale este dorit de Luis Enrique la echipa din Paris, scrie Fichajes, una dintre cele mai renumite publicații sportive din lume.\nGigi Becali a primit un spor de pedeapsă de 6 luni la cei 3 ani pe care îi avea deja de executat.[8] La aflarea veștii, aflat în boxa arestaților, Becali a trimis toată România în iad, iar la final și-a cerut scuze.[9]\nBănel Nicoliță (n. 7 ianuarie 1985, Făurei, Brăila, România) este un fotbalist român cunoscut pentru activitatea sa la FCSB. Este al doilea stelist ca număr de meciuri (64) în competițiile europene, după Marius Lăcătuș (72).\n\nIntrebare: A marcat vreodata Banel Nicolita un autogol?\nRaspuns:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"042ce9ba063b417d9a7880b87db102c7"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nDorinel Munteanu nu mai este antrenorul echipei Oțelul Galați. Tehnicianul a demisionat, fiind nemulțumit de probleme financiare ale echipei. Anunțul a fost făcut de Cristian Munteanu, președinte echipei:\nDorinel Munteanu a lăsat de înțeles, de mai multe ori pe parcursul acestui sezon că urmează să plece de la echipă, însă nu acum, ci în iunie, la finalul sezonului. Alături de el, de la Oțelul Galați vor pleca mai mulți jucători. Alexandru Pop este aproape de un transfer la Dinamo, iar Juri Cisotti poate ajunge la FCSB.\nÎn 2011, cu Dorinel Munteanu pe bancă, Otelul Galați devenea campiona României și ajungea în grupele Ligii Campionilor. Ulterior, echipa a dat faliment. În 2021, Dorinel Munteanu revenea la Galați, preluând echipa din liga a treia. Lasă echipa pe locul 11, în prima divizie.\n„Cu părere de rău, e adevărat, a plecat. Motivul este situația financiară de la club, dar eu sunt ultra, ultra convins că o scoatem la capăt și de data asta. I-am zis și lui, am sperat până în ultima clipă că va rămâne, dar n-a mai putut. Mi-a zis încă de la meciul cu UTA că el vrea să plece\".\nEl ar putea ajunge la FC Voluntari, în a doua divizie. Echipa din Ilfov l-a demis recent pe Ovidiu Burcă. În schimb, la Galați ar putea ajunge Tony da Silva, portughez ce a fost ultima oară pe banca celor de la Poli Iași. A fost ofertat și Daniel Oprița, în prezent la CSA Steaua, însă acesta a refuzat.\n\nIntrebare: Din ce cauza a demisionat Dorinel Munteanu?\nRaspuns:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a22ded7e19134527b226e70c9eb379a1"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nRadu Dragușin a primit o ofertă de la PSG și ar putea pleca de la Tottenham. Fundașul echipei naționale este dorit de Luis Enrique la echipa din Paris, scrie Fichajes, una dintre cele mai renumite publicații sportive din lume.\nMai mult, potrivit sursei citate, fundașul central, în vârstă de 22 de ani, ar putea fi cumpărat de PSG pentru 50 de milioane de euro. Dacă transferul se va concretiza, ar deveni cel mai scump jucător român din istorie.\nÎn iarna 1986/1987, Gheorghe Hagi a fost împrumutat la proaspăt campioana Europei de atunci, Steaua București, în vederea cooptării în lotul pentru partida cu Dinamo Kiev din Supercupa Europei. Deși contractul inițial a fost doar pentru acest meci, după ce Hagi a fost autorul singurului gol, victorios, el a fost transferat definitiv.\nEl ar putea ajunge la FC Voluntari, în a doua divizie. Echipa din Ilfov l-a demis recent pe Ovidiu Burcă. În schimb, la Galați ar putea ajunge Tony da Silva, portughez ce a fost ultima oară pe banca celor de la Poli Iași. A fost ofertat și Daniel Oprița, în prezent la CSA Steaua, însă acesta a refuzat.\nLa 7 mai 2008, George Becali a oferit suma de 1,7 milioane de euro jucătorilor de la Universitatea Cluj - cca. 100.000 de euro pentru fiecare jucător - pentru ca aceștia să-și apere corect șansele și astfel să câștige meciul cu CFR 1907 Cluj. Acesta era ultimul meci din Liga I, dacă CFR Cluj pierdea meciul, Steaua București câștiga titlul de campioană.[4]\n\nIntrebare: Care este suma de transfer zvonita pentru Radu Dragusin?\nRaspuns:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2150eab80555462a9f8f23ab19570473"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nSir Alexander Chapman \"Alex\" Ferguson, CBE (n. 31 decembrie 1941, Govan⁠(d), Scoția, Regatul Unit) este un antrenor scoțian de fotbal, fost atacant, fost antrenor al echipei Manchester United F.C. și în prezent retras din activitate. A câștigat mai multe trofee decât oricare alt antrenor din istoria fotbalului englez, și a condus de pe bancă pe Manchester United în peste 1000 de meciuri. Cu 26 de ani petrecuți la acest club, este cel mai longeviv antrenor din istoria lui Manchester United, depășindu-l pe „Sir”, Matt Busby, și este considerat unul dintre cei mai mari antrenori ai fotbalului modern.\nLa Manchester, Sir Alex a devenit cel mai de succes antrenor din istoria fotbalului englez, câștigând nouă titluri de campioană. În 1999, a devenit primul antrenor care a condus o echipă din Anglia spre o triplă Premiership-Cupă FA-Liga Campionilor. Pe lângă faptul că e singurul antrenor care a câștigat de cinci ori Cupa FA, este de asemenea singurul antrenor din istorie care a câștigat trei campionate la rând în Anglia cu aceeași echipă (1998-1999, 1999-2000, 2000-2001).\nUn leitmotiv al carierei lui Ferguson la Manchester United a fost faptul că nici un jucător nu a fost considerat mai important decât echipa. A fost foarte intransigent în relațiile sale cu jucătorii, și presiunea acestei tactici manageriale a determinat multe vedete să plece. De-a lungul anilor, jucători precum Gordon Strachan, Paul McGrath, Paul Ince, Jaap Stam, Dwight Yorke, David Beckham, și, mai recent, Ruud van Nistelrooy sau Gabriel Heinze, au plecat de la club în urma unor conflicte mai mult sau mai puțin grave cu Ferguson. Se consideră că disciplina impusă unor jucători foarte bine cunoscuți și plătiți a fost un factor determinant în succesul constant al lui Manchester în era Ferguson.\nA mai antrenat pe East Stirlingshire și St. Mirren, înainte de o perioadă foarte bună la echipa scoțiană Aberdeen F.C.. A fost pentru scurt timp antrenorul echipei naționale de fotbal a Scoției, fiind numit interimar după moartea lui Jock Stein, iar în 1986 a fost numit antrenor la Manchester United.\nLa 24 octombrie 2013, Ferguson și-a publicat a doua autobiografie, intitulată Alex Ferguson: My Autobiography, unde relatează atât experiența sa ca manager, cât și aspecte din cadrul familiei sale.\n\nIntrebare: Cate titluri de campioana a Angliei a castigat Sir Alex Ferguson cu Manchester United?\nRaspuns:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8288ec6547c84744a48f449e5dbb0c9d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nTotuși, DNA a declanșat urmărirea penală față de Becali, Teia Sponte și alții, iar dosarul a ajuns în instanță la sfârșitul anului 2008. Primul termen a avut loc la 21 ianuarie 2009 la Curtea de Apel Cluj. În continuare, procesul a fost mutat la Înalta Curte de Casație și Justiție, ca urmare a cererii avocaților inculpaților.\nProcurorii DNA au interceptat valiza cu bani într-un restaurant din Cluj unde oficiali ai Stelei așteptau rezultatul meciului pentru a da sau nu banii. Cu toate acestea, CFR a câștigat cu 1-0 și a devenit campioană a României, valiza rămânând fără destinatar.[5]\nPe 4 iunie 2013, Înalta Curte de Casație și Justiție a dat sentința definitivă, condamnându-l pe George Becali la trei ani de închisoare cu executare, pentru dare de mită și pentru fals, iar pe Teia Sponte la doi ani cu suspendare și pe Victor Pițurcă la un an de închisoare cu suspendare.[6][7]\nGigi Becali a primit un spor de pedeapsă de 6 luni la cei 3 ani pe care îi avea deja de executat.[8] La aflarea veștii, aflat în boxa arestaților, Becali a trimis toată România în iad, iar la final și-a cerut scuze.[9]\nÎn minutul 73, FCSB a preluat conducerea, Adrian Șut a marcând din nou. Mijlocașul a câștigat un duel aerian cu Akhundzade și a trimis balonul în plasă, cu capul.\n\nIntrebare: Cine sunt inculpatii in dosarul valiza?\nRaspuns:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb60d2cfacd4bb08cb27d7d44d11bda"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nSupranumit \"Maradona din Carpați\", Hagi este considerat un erou în România. A fost numit fotbalistul român al anului de șapte ori, și este privit ca unul dintre cei mai buni fotbaliști ai generației sale. Ca un constructor de joc avansat, a fost recunoscut pentru dribling, tehnică, viziune, pase și finalizare.\nGheorghe Hagi (n. 5 februarie 1965, Săcele, Constanța, România) este un fost fotbalist român, considerat unul dintre cei mai buni mijlocași ofensivi în Europa anilor '80 și '90 și cel mai mare fotbalist român din toate timpurile. Fanii lui Galatasaray l-au numit \"Comandante\" (Comandantul) și românii l-au numit \"Regele\".\nÎn cei patru ani petrecuți în roșu-albastru, Gică Hagi s-a consacrat definitiv în fotbalul internațional. Și-a înscris în palmares 3 titluri de campion cu Steaua (1987, 1988 și 1989), 3 cupe ale României în aceiași ani precum și Supercupa Europei din 1987. Cu Steaua a rămas în topul echipelor din Europa, unde a ajuns în semifinala CCE din 1988, echipa fiind eliminată de Benfica și în finala CCE din 1989, pierdută în fața echipei italiene AC Milan (fiind desemnat al doilea jucător ca valoare din competiție, după Marco van Basten). La nivelul echipei naționale, participă cu România la Cupa Mondială din 1990 - Italia.\nRadu Dragușin a primit o ofertă de la PSG și ar putea pleca de la Tottenham. Fundașul echipei naționale este dorit de Luis Enrique la echipa din Paris, scrie Fichajes, una dintre cele mai renumite publicații sportive din lume.\nÎn iarna 1986/1987, Gheorghe Hagi a fost împrumutat la proaspăt campioana Europei de atunci, Steaua București, în vederea cooptării în lotul pentru partida cu Dinamo Kiev din Supercupa Europei. Deși contractul inițial a fost doar pentru acest meci, după ce Hagi a fost autorul singurului gol, victorios, el a fost transferat definitiv.\n\nIntrebare: Care este porecla lui Gica Hagi data de catre romani?\nRaspuns:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12490be62bed4881a6687e31fec8798a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt Sent to LLM:\nFolosind doar informatiile oferite mai jos, raspunde clar si exact la intrebare.\nInformatii disponibile:\nFCSB a câștigat meciul cu Qarabag, din etapa a 7-a a grupei principale din UEFA Europa League.\nÎn urma acestei victorii, șansele pentru o calificare directă în optimile competiției cresc. FCSB o va întâlni pe Manchester United în ultima etapă a fazei grupelor principale.\nÎn minutul 73, FCSB a preluat conducerea, Adrian Șut a marcând din nou. Mijlocașul a câștigat un duel aerian cu Akhundzade și a trimis balonul în plasă, cu capul.\nReplica FCSB-ului a venit șase minute mai târziu, prin golul căpitanului Adrian Șut, care a înscris cu o lovitură de cap de la 6 metri, în urma unui corner executat de Florin Tănase.\nScorul s-a schimbat din nou în minutul 41, când Qarabag a revenit în avantaj după ce fundașul stânga Jafarguliyev a centrat puternic în fața porții, iar mingea s-a lovit de Dawa și a intrat în propria poartă.\n\nIntrebare: Este adevarat ca a castigat echipa FCSB impotriva celor de la Qarabag?\nRaspuns:\nQuestion:\nA marcat vreodata Banel Nicolita un autogol?\nGround Truth:\nDa, Banel Nicolita a marcat un autogol impotriva echipei Real Madrid.\nIR + LLM response:\n Da, Banel Nicolita a marcat un autogol in timpul unui meci din Liga Campionilor 2006-2007 dintre Real Madrid si FCSB.\nROUGE-L: 0.5625\n===========================================================================\nQuestion:\nDin ce cauza a demisionat Dorinel Munteanu?\nGround Truth:\nDorinel Munteanu a demisionat din cauza unor probleme financiare ale clubului.\nIR + LLM response:\n Dorinel Munteanu a demisionat din cauza problemelor financiare ale echipei.\nROUGE-L: 0.761904761904762\n===========================================================================\nQuestion:\nCare este suma de transfer zvonita pentru Radu Dragusin?\nGround Truth:\nPSG ar putea plati 50 de milioane de euro pentru transferul lui Radu Dragusin.\nIR + LLM response:\n 50 de milioane de euro.\nROUGE-L: 0.5263157894736842\n===========================================================================\nQuestion:\nCate titluri de campioana a Angliei a castigat Sir Alex Ferguson cu Manchester United?\nGround Truth:\nNoua titluri de campioana a Angliei.\nIR + LLM response:\n Noua titluri de campioana a Angliei a castigat Sir Alex Ferguson cu Manchester United.\nROUGE-L: 0.6\n===========================================================================\nQuestion:\nCine sunt inculpatii in dosarul valiza?\nGround Truth:\nInculpatii din dosarul Valiza sunt George Becali, Teia Ponte si Victor Piturca.\nIR + LLM response:\n George Becali, Teia Sponte si Victor Piturca.\nROUGE-L: 0.631578947368421\n===========================================================================\nQuestion:\nCare este porecla lui Gica Hagi data de catre romani?\nGround Truth:\nPorecla acestuia este regele.\nIR + LLM response:\n Regele\n\nExplicatie: Informatiile oferite arata ca Gheorghe Hagi este considerat un erou in Romania si este privit ca unul dintre cei mai buni fotbalisti ai generatiei sale. El este, de asemenea, cunoscut sub numele de „Maradona din Carpați”. Prin urmare, porecla lui Gheorghe Hagi dată de români este „Regele”.\nROUGE-L: 0.10909090909090909\n===========================================================================\nQuestion:\nEste adevarat ca a castigat echipa FCSB impotriva celor de la Qarabag?\nGround Truth:\nDa, FCSB a castigat impotriva celor de la Qarabag.\nIR + LLM response:\n Da, FCSB a castigat impotriva celor de la Qarabag.\nROUGE-L: 1.0\n===========================================================================\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}